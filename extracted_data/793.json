{
  "id": "793",
  "title": "Surprisal-Driven Feedback in Recurrent Networks",
  "abstract": "Recurrent neural nets are widely used for predicting temporal data. Their inherent deep feedforward structure allows learning complex sequential patterns. It is believed that top-down feedback might be an important missing ingredient which in theory could help disambiguate similar patterns depending on broader context. In this paper, we introduce surprisal-driven recurrent networks, which take into account past error information when making new predictions. This is achieved by continuously monitoring the discrepancy between most recent predictions and the actual observations. Furthermore, we show that it outperforms other stochastic and fully deterministic approaches on enwik8 character level prediction task achieving 1.37 BPC.",
  "accepted": false,
  "zeroShot": [
    {
      "model": "claude-haiku-4-5",
      "decision": {
        "rejection": true,
        "confidence": 0.85,
        "primary_reason": "Limited novelty and experimental validation. The core contribution—adding surprisal (prediction error) as feedback to RNNs—is a straightforward architectural modification lacking theoretical justification. Experiments are restricted to a single dataset (enwik8) with no ablation studies, statistical significance testing, or comparison with contemporary methods. The writing quality is poor with grammatical errors and incomplete related work section. Missing critical details on baseline implementations and hyperparameter tuning. The claimed improvement (1.37 BPC) lacks proper contextualization and the paper provides no analysis of when/why the feedback helps."
      },
      "token": {
        "prompt_tokens": 2356,
        "completion_tokens": 162,
        "total_tokens": 2518
      },
      "time": "2026-02-05T23:20:14.706717+00:00"
    },
    {
      "model": "gpt-5.2",
      "decision": {
        "rejection": true,
        "confidence": 0.78,
        "primary_reason": "Insufficient methodological rigor and experimental evidence: the idea is close to known dynamic evaluation/error-feedback schemes, and results are reported only on enwik8 with limited ablations, baselines, and reproducibility details to substantiate a top-tier conference claim."
      },
      "token": {
        "prompt_tokens": 1994,
        "completion_tokens": 69,
        "total_tokens": 2063
      },
      "time": "2026-02-09T21:48:53.057007+00:00"
    }
  ],
  "article": [
    {
      "heading": "1 INTRODUCTION",
      "text": "Based on human performance on the same task, it is believed that an important ingredient which is missing in state-of-the-art variants of recurrent networks is top-down feedback. Despite evidence of its existence, it is not entirely clear how mammalian brain might implement such a mechanism. It is important to understand what kind of top-down interaction contributes to improved prediction capability in order to tackle more challenging AI problems requiring interpretation of deeper contextual information. Furthermore, it might provide clues as what makes human cognitive abilities so unique. Existing approaches which consider top-down feedback in neural networks are primarily focused on stacked layers of neurons, where higher-level representations constitute a top-down signal source. In this paper, we propose that the discrepancy between most recent predictions and observations might be effectively used as a feedback signal affecting further predictions. It is very common to use such a discrepancy during learning phase as the error which is subject to minimization, but not during inference. We show that is also possible to use such top-down signal without losing generality of the algorithm and that it improves generalization capabilities when applied to Long-Short Term Memory (Hochreiter & Schmidhuber, 1997) architecture. It is important to point out that the feedback idea presented here applies only to temporal data.",
      "exclude": true
    },
    {
      "heading": "1.1 SUMMARY OF CONTRIBUTIONS",
      "text": "The main contributions of this work are: the introduction of a novel way of incorporating most recent misprediction measure as an additional input signal extending state-of-the-art performance on character-level text modeling using Hutter Wikipedia dataset.",
      "exclude": false
    },
    {
      "heading": "1.2 RELATED WORK",
      "text": "There exist other approaches which attempted to introduce top-down input for improving predictions. One such architecture is Gated-Feedback RNN (Chung et al., 2015). An important difference between architecture proposed here and theirs is the source of the feedback signal. In GF-RNN it is assumed that there exist higher level representation layers and they constitute the feedback source. On the other hand, here, feedback depends directly on the discrepancy between past predictions and current observation and operates even within a single layer. Another related concept is Ladder Networks (Rasmus et al., 2015), where top-down connections contribute to improved semi-supervised learning performance.",
      "exclude": true
    },
    {
      "heading": "2 FEEDBACK: MISPREDICTION-DRIVEN PREDICTION",
      "text": "",
      "exclude": false
    },
    {
      "heading": "2.1 NOTATION",
      "text": "The following notation is used throughout the section: x - inputs h - hidden units y - outputs p - output probabilities (normalized y) s - surprisal t - time step W - feedforward x h connection matrix U - recurrent h h connection matrix V - feedback s h connection matrix S - truncated BPTT length M - number of inputs N - number of hidden units denotes matrix multiplication denotes elementwise multiplication (), tanh() - elementwise nonlinearities x = Ex In case of LSTM, the following concatenated representations are used: gt = itftot ut b = b i bf bo bu U = U i Uf Uo Uu W = W i Wf Wo Wu V = V i Vf Vo Vu (1)",
      "exclude": false
    },
    {
      "heading": "2.2 SIMPLE RNN WITHOUT FEEDBACK",
      "text": "First, we show a simple recurrent neural network architecture without feedback which serves as a basis for demonstrating our approach. It is illustrated in Fig. 2 and formulated as follows: ht = tanh(W xt + U ht1 + b) (2)",
      "exclude": false
    },
    {
      "heading": "2.3 FEEDBACK AUGMENTED RECURRENT NETWORKS",
      "text": "Figure 3 presents the main idea of surprisal-driven feedback in recurrent networks. In addition to feedforward and recurrent connections W and U , we added one additional matrix V . One more input signal, namely V st is being considered when updating hidden states of the network. We propose that the discrepancy st between most recent predictions pt1 and observations xt might be effectively used as a feedback signal affecting further predictions. Such information is usually used during learning phase as an error signal, but not during inference. Our hypothesis is that it represents an important source of information which can be used during the inference phase, should be used and that it bring benefits in the form of improved generalization capability. Figure 1 presents examples of feedback signal being considered. Intuitively, when surprisal is near zero, the sum of input signals is the same as in a typical RNN. Next subsections provide mathematical description of the feedback architecture in terms of forward and backward passes for the Back Propagation Through Time (BPTT) (Werbos, 1990) algorithm.",
      "exclude": false
    },
    {
      "heading": "2.4 FORWARD PASS",
      "text": "Set h0, c0 to zero and p0 to uniform distribution or carry over the last state to emulate full BPTT. i, pi0 = 1 M , i 0, 1, ..,M 1, t = 0 (3) for t = 1:1:S-1 I. Surprisal part st = i log pit1 xit (4) IIa. Computing hidden activities, Simple RNN ht = tanh(W xt + U ht1 + V st + b) (5) IIb. Computing hidden activities, LSTM (to be used instead of IIa) ft = (Wf xt + Uf ht1 + Vf st + bf ) (6) it = (W i xt + U i ht1 + Vi st + bi) (7) ot = (Wo xt + Uo ht1 + Vo st + bo) (8) ut = tanh(Wu xt + Uu ht1 + Vu st + bu) (9) ct = (1 ft) ct1 + it ut (10) ct = tanh(ct) (11) ht = ot ct (12) III. Outputs yit =Wy ht + by (13) Softmax normalization pit = ey i ti ey i t (14)",
      "exclude": false
    },
    {
      "heading": "2.5 BACKWARD PASS",
      "text": "for t = S-1:-1:1 I. Backprop through predictions Backprop through softmax, cross-entropy error, accumulate Et yt = Et yt + pt1 xt (15) y Wy, by E Wy = E Wy + hTt Et yt (16) E by = E by + M i=1 Eit yit (17) y h Et ht = Et ht + Et yt WTy (18) IIa. Backprop through hidden nonlinearity (simple RNN version) Et ht = Et ht + Et ht tanh(ht) (19) Et gt = Et ht (20) IIb. Backprop through c, h, g (LSTM version) Backprop through memory cells, (keep gradients from the previous iteration) Et ct = Et ct + Et ht ot tanh(ct) (21) Carry error over to Etct1 Et ct1 = Et ct1 + Et ct (1 ft) (22) Propagate error through the gates Et ot = Et ht ct (ot) (23) Et it = Et ct ut (it) (24) Et ft = Et ct ct1 (ft) (25) Et ut = Et ct it tanh(ut) (26) Carry error over to Etht1 Et ht1 = Et gt UT (27) III. Backprop through linearities Et b = Et b + N i=1 Et git (28) E U = E U + hTt1 Et gt (29) E W = E W + xTt Et gt (30) E x = E x + Et gt WT (31) IV. Surprisal part E V = E V + sTt Et gt (32) E st = E gt V T (33) Et pt1 = Et st xt (34) Adjust Etpt1 according to the sum of gradients and carry over to Et yt1 Et yt1 = Et pt1 pt1 M i=1 Et pit1 (35)",
      "exclude": false
    },
    {
      "heading": "3 EXPERIMENTS",
      "text": "We ran experiments on the enwik8 dataset. It constitutes first 108 bytes of English Wikipedia dump (with all extra symbols present in XML), also known as Hutter Prize challenge dataset2. First 90% of each corpus was used for training, the next 5% for validation and the last 5% for reporting test accuracy. In each iteration sequences of length 10000 were randomly selected. The learning algorithm used was Adagrad1 with a learning rate of 0.001. Weights were initialized using so-called Xavier initialization Glorot & Bengio (2010). Sequence length for BPTT was 100 and batch size 128, states were carried over for the entire sequence of 10000 emulating full BPTT. Forget bias was set initially to 1. Other parameters set to zero. The algorithm was written in C++ and CUDA 8 and ran on GTX Titan GPU for up to 10 days. Table 1 presents results comparing existing state-of-theart approaches to the introduced Feedback LSTM algorithm which outperforms all other methods despite not having any regularizer.",
      "exclude": false
    },
    {
      "heading": "4 SUMMARY",
      "text": "We introduced feedback recurrent network architecture, which takes advantage of temporal nature of the data and monitors the discrepancy between predictions and observations. This prediction error 1with a modification taking into consideration only recent window of gradient updates 2http://mattmahoney.net/dc/text.html 3This method does not belong to the dynamic evaluation group: 1. It never actually sees test data during training. 2. It does not adapt weights during testing 4our implementation information, also known as surprisal, is used when making new guesses. We showed that combining commonly used feedforward, recurrent and such feedback signals improves generalization capabilities of Long-Short Term Memory network. It outperforms other stochastic and fully deterministic approaches on enwik8 character level prediction achieving 1.37 BPC.",
      "exclude": false
    },
    {
      "heading": "5 FURTHER WORK",
      "text": "It is still an open question what the feedback should really constitute as well as how it should interact with lower-level neurons (additive, multiplicative or another type of connection). Further improvements may be possible with the addition of regularization. Another research direction is incorporating sparsity in order improve disentangling sources of variation in temporal data.",
      "exclude": false
    },
    {
      "heading": "ACKNOWLEDGEMENTS",
      "text": "This work has been supported in part by the Defense Advanced Research Projects Agency (DARPA).",
      "exclude": false
    }
  ],
  "fewShot": [
    {
      "model": "gpt-5.2",
      "decision": {
        "rejection": true,
        "confidence": 0.9,
        "primary_reason": "The core idea—feeding last-step prediction error/surprisal back into the RNN/LSTM state update—is incremental and insufficiently motivated/validated, with evaluation essentially limited to enwik8 and lacking strong baselines, ablations, and analysis to convincingly establish when/why the feedback helps or that the reported gains are fair and broadly impactful."
      },
      "token": {
        "prompt_tokens": 4628,
        "completion_tokens": 98,
        "total_tokens": 4726
      },
      "time": "2026-02-09T20:54:31.739346+00:00"
    },
    {
      "model": "claude-haiku-4-5",
      "decision": {
        "rejection": true,
        "confidence": 0.92,
        "primary_reason": "Incremental architectural modification (adding prediction-error feedback) with weak empirical validation: single dataset (enwik8), unclear baselines, no ablations, missing implementation details (model size, fair comparisons), and insufficient analysis of when/why feedback helps. The core contribution—feeding last-step surprisal as input—lacks novelty and rigorous justification."
      },
      "token": {
        "prompt_tokens": 5252,
        "completion_tokens": 114,
        "total_tokens": 5366
      },
      "time": "2026-02-11T19:31:24.882559+00:00"
    }
  ],
  "test": false
}