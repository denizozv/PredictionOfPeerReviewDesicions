{
  "id": "563",
  "title": "b-GAN: Unified Framework of Generative Adversarial Networks",
  "abstract": "Generative adversarial networks (GANs) are successful deep generative models. They are based on a two-player minimax game. However, the objective function derived in the original motivation is changed to obtain stronger gradients when learning the generator. We propose a novel algorithm that repeats density ratio estimation and f-divergence minimization. Our algorithm offers a new unified perspective toward understanding GANs and is able to make use of multiple viewpoints obtained from the density ratio estimation research, e.g. what divergence is stable and relative density ratio is useful.",
  "accepted": false,
  "zeroShot": [
    {
      "model": "claude-haiku-4-5",
      "decision": {
        "rejection": false,
        "confidence": 0.72,
        "primary_reason": "Novel theoretical framework connecting GANs to density ratio estimation with solid mathematical foundation and experimental validation, though limited experimental scope and incremental practical improvements over f-GAN"
      },
      "token": {
        "prompt_tokens": 9698,
        "completion_tokens": 61,
        "total_tokens": 9759
      },
      "time": "2026-02-05T22:59:20.911306+00:00"
    }
  ],
  "article": [
    {
      "heading": "1 INTRODUCTION",
      "text": "There have been many recent studies about deep generative models. Generative adversarial networks (GAN) (Goodfellow et al., 2014) is the variant of these models that has attracted the most attention. It has been demonstrated that generating vivid, realistic images from a uniform distribution is possible (Radford et al., 2015; Denton et al., 2015). GANs are formulated as a two-player minimax game. However, the objective function derived in the original motivation is modified to obtain stronger gradients when learning the generator. GANs have been applied in various studies; however, few studies have attempted to reveal their mechanism (Goodfellow, 2014; Huszar, 2015). Recently, f-GAN, which minimizes the variational estimate of f-divergence, has been proposed (Nowozin et al., 2016). The original GAN is a special case of f-GAN. In this study, we propose a novel algorithm inspired by GANs from the perspective of density ratio estimation based on the Bregman divergence, which we refer to as b-GAN. The proposed algorithm iterates density ratio estimation and f-divergence minimization based on the obtained density ratio. This study make the following two primary contributions: 1. We derive a novel unified algorithm that employs well-studied results regarding density ratio estimation (Kanamori et al., 2012; Sugiyama et al., 2012; Menon & Ong, 2016). 2. In the original GANs, the value function derived from the two-player minimax game does not match the objective function that is actually used for learning the generative model. In our algorithm, the objective function derived from the original motivation is not changed for learning the generative model. The remainder of this study is organized as follows. Section 2 describes related work. Section 3 introduces and analyzes the proposed algorithm in detail. Section 4 explains the proposed algorithm for specific cases. Section 5 reports experimental results. Section 6 summarizes our findings and discusses future work.",
      "exclude": true
    },
    {
      "heading": "2 RELATED WORK",
      "text": "In this study, we denote an input space as X and a hidden space as Z. Let p(x) be the distribution of training data over X and q(x) be the generated distribution over X . GANs (Goodfellow et al., 2014) were developed based on a game theory scenario, where two model, i.e., a generator network and a discriminator network, are simultaneously trained. The generator network GG(z) produces samples with a probability density function of q(x; G). The discriminator network TD (x) attempts to distinguish the samples from the training samples and that from the generator. GANs are described as a zero-sum game, where the function v(G,T ) determines the pay-off of the discriminator and the function v(G,T ) determines the pay-off of the generator. The discriminator TD (x) and generator GG(z) play the following two-player minimax game minG maxD v(G,T ), where v(G,T ) can be expressed as follows: Exp(x)[log TD (x)] + Exq(x;G)[log(1 TD (x))]. The discriminator and generator are iteratively trained by turns. For fixed G, the optimal T(x) is p(x)p(x)+q(x) . This suggests that training the discriminator can be formulated as a density ratio estimation. The generator is trained to minimize v(G,T ) adversarially. In fact, maximizing Exq(x;G)[log TD (x)] is preferable instead of minimizing Exq(x;G)[log(1 TD (x))]. Although this does not match the theoretical motivation, this heuristic is the key to successful learning. We analyze this heuristic in Section 3.4. f-GAN (Nowozin et al., 2016) generalizes the GAN concept. First, we introduce f-divergence (Ali & Silvey, 1966). The f-divergence measures the difference between two probability distributions p and q and is defined as Df (p||q) = q(x)f ( p(x) q(x) ) dx = q(x)f (r(x)) dx, (1) where f(x) is a convex function satisfying f(1) = 0. Note that in the space of positive measures, i.e., not satisfying normalized conditions, f-divergence must satisfy f (1) = 0 due to its invariance (Amari & Cichoki, 2010). The function v(G,T ) of f-GAN is given by Exp(x)[TD (x)] Exq(x;G)[f (TD (x))], (2) where f is a Fenchel conjugate of f (Nguyen et al., 2010). In Eq. 2, v(G,T ) comes from, q(x)f ( p(x) q(x) ) dx = sup T Exp[T (x)] Exq[f(T (x))]. (3) Following GANs, D is trained to maximize Eq. 2 in order to estimate the f-divergence. In contrast, G is trained to adversarially minimize Eq. 2 to minimize the f-divergence estimate. However, as in GANs, maximizing Exq[T (x)] is used rather than minimizing Exq[f(T (x))]. The latter optimization is theoretically valid in their formulation; however, they used the former heuristically. Similar to GANs, f-GAN also formulates the training discriminator as a density ratio estimation. For a fixed G, the optimal T (x) is f (pq ), where f denotes the first-order derivative of f . When f(x) is x log x (x+ 1) log(1 +x), f-GANs are equivalent to GANs. Table 1 summarizes GAN and f-GAN. We denote the step for updating D as D-step and the step for updating G as G-step.",
      "exclude": true
    },
    {
      "heading": "3 METHOD",
      "text": "As described in Section 2, training the discriminators in the D-step of GANs and f-GANs is regarded as density ratio estimation. In this section, we further extend this idea. We first review the density ratio estimation method based on the Bregman divergence. Then, we explain and analyze a novel proposed b-GAN algorithm. See appendix E for recent research related to density ratio estimation.",
      "exclude": false
    },
    {
      "heading": "3.1 DENSITY RATIO MATCHING UNDER THE BREGMAN DIVERGENCE",
      "text": "There have been many studies on direct density ratio estimation, where a density ratio model is fitted to a true density ratio model under the Bregman divergence (Sugiyama et al., 2012). We briefly review this method. Assume there are two distributions p(x) and q(x). Our aim is to directly estimate the true density ratio r(x) = p(x)q(x) without estimating p(x) and q(x) independently . Let r(x) be a density ratio model. The integration of the Bregman divergence Bf [r(x)r(x)] between the density ratio model and the true density ratio with respect to measure q(x)dx is BDf (r||r) = Bf [r(x)r(x)]q(x)dx = (f(r(x)) f (r(x)) f (r(x)) (r(x) r(x))) q(x)dx. (4) We define the terms related to r in BDf (r||r) as BRf (r) = (f (r(x))r(x) f(r(x))) q(x)dx f (r(x)) p(x)dx (5) = f (r(x)) (r(x)q(x) p(x)) dxDf (qrq). (6) Thus, estimating the density ratio problem turns out to be the minimization of Eq. 5 with respect to .",
      "exclude": false
    },
    {
      "heading": "3.2 MOTIVATION",
      "text": "In this section, we introduce important propositions required to derive b-GAN. Proofs of propositions are given in Appendix C. The following proposition suggests that the supremum of the negative of Eq. 5 is equal to the f-divergence between p(x) and q(x). Prop 3.1. The following equation holds: Eq [ f ( p(x) q(x) )] = sup r Exp[f (r(x))] Exq[(f (r(x))r(x) f(r(x)))]. (7) The right side of Eq. 7 reaches the supremum when r(x) = r(x) is satisfied. It has been shown that the supremum of negative of Eq. 5 is equivalent to the supremum of Eq. 2. Interestingly, the negative of Eq. 5 has a dual relation with the objective function of f-GAN, i.e., Eq. 2. Prop 3.2. Introducing dual coordinates TD = f (r)(Amari & Cichoki, 2010) yields the right side of Eq. 5 from Eq. 2. Prop 3.2 shows that the D-step of f-GAN can be regarded as the density ratio estimation because Eq. 5 expresses the density ratio estimation and Eq. 2 is a value function of f-GAN.",
      "exclude": false
    },
    {
      "heading": "3.3 B-GAN",
      "text": "Our objective is to minimize the f-divergence between the distribution of the training data p(x) and the generated distribution q(x). We introduce two functions constructed using neural networks: rD (x) : X R parameterized by D, and GG(z) : Z X parameterized by G. Measure q(x; G)dx is a probability measure induced from the uniform distribution by GG(z). In this case, rD (x) is regarded as a density ratio estimation network and GG(z) is regarded as a generator network for minimizing the f-divergence between p(x) and q(x). Motivated by Section 3.2, we construct a b-GAN using the following two steps. 1. Update D to estimate the density ratio between p(x) and q(x; G). To achieve this, we minimize Eq. 5 with respect to r(x). In this step, the density ratio model r(x) in Eq. 5 can be considered as rD (x) in this step. 2. Update G to minimize the f-divergence Df (p||q) between p(x) and q(x; G) using the obtained density-ratio. We are able to suppose that q(x; G)r(x) is close to p(x). Instead of Df (p||q), we update G to minimize the empirical approximation of Df (qr||q). The b-GAN algorithm is summarized in Algorithm 1, where B is the batch size. In this study, a single-step gradient method (Goodfellow et al., 2014; Nowozin et al., 2016) is adopted. Algorithm 1: b-GAN for number of training iterations do sample X = x1, ..., xB from p(x) and Z = z1, ..., zB from an uniform distribution. D-step: Update D: t+1D = t D D ( 1 B B i=1 f ( rD (G(zi)) ) rD (G(zi)) f ( rD (G(zi)) ) f ( rD (xi) )) . G-step: Update G: t+1G = t G G ( 1 B B i=1 f ( r(GG(zi)) )) . end for In the D-step, the proposed algorithm estimates pq toward any divergence; thus, it differs slightly from the D-step of f-GAN because the estimated values, i.e., f (pq ), are dependent on the divergences. We also introduce an f-GAN-like update as follows. As mentioned in Section 2, we have two options in the G step. 1. D-step: minimize Exp(x)[f (rD (x))] +Exq(x)[f (rD (x))rD (x) f(rD (x))] w.r.t D. 2. G-step: minimize Exq(x;G)[f (r(x))] or Exq(x;G)[f (r(x))r(x) + f(r(x))] w.r.t G.",
      "exclude": false
    },
    {
      "heading": "3.4 ANALYSIS",
      "text": "Following Goodfellow et al. [2014], we explain the validity of the G-step and D-step. We then explain the meaning of b-GAN. Finally, we analyze differences between b-GAN and f-GAN. The density ratio is estimated in the D-step. The estimator of r(x) is an M-estimator and is asymptotically consistent under the proper normal conditions (Appendix E.1). In the G-step, we update the generator as minimizing Df (p||q) by replacing p(x) with r(x)q(x). We assume that q(x; G) is equivalent to p(x) when G = , q(x; G) is identifiable, and the optimal r(x) is obtained in the D-step. By our assumption, the acquired value in the G-step is , which minimizes the empirical approximation of Df (r(x)q(x; G)q(x; G)) = Exq(x;G)[r(x)]. When G is equal to , this equation is equal to 0. The estimator can be considered as a kind of Z-estimator. Usually, we cannot perform only a G-step because we do not know the form of p(x) and q(x). In b-GAN, Df (p||q) can be minimized by estimating the density ratio r(x) without estimating the densities directly. In fact, the r(x) obtained at each iteration is different and not optimal because we adopt a single-step gradient method (Nowozin et al., 2016). Thus, b-GAN dynamically updates the generator to minimize the f-divergence between p(x) and q(x). As mentioned previously, f(x) must satisfy f (1) = 0 in this case because we cannot guarantee that r(x)q(x) is normalized. Similar to GANs, the D-step and G-step work adversarially. In the D-step, r(x) is updated to fit the ratio between p(x) and q(x). In the G-step, q(x) changes, which means r(x) becomes inaccurate in terms of the density ratio estimator. Next, r(x) is updated in the D-step so that it fits the density ratio of p(x) and the new q(x). This learning situation is derived from Eq. 6 , which shows that D is updated to increase Df (qrq) in the D-step. In contrast, G is updated to decrease Df (qrq) in the G-step. In Section 3.3, we also introduced a f-GAN-like update. Three choices can be considered for the G-step: (1)Exq(x:G)[f(r(x))], (2)Exq(x;G)[f (r(x))], (3)Exq(x;G)[f (r(x))r(x) + f(r(x))]. Note that f is a convex function, f(1) = 0, and f (1) = 0. It is noted in (Nowozin et al., 2016) that case (2) works better than case (3) in practice. We also confirm this. The complete reason for this is unclear. However, we can find a partial reason by differentiating objective functions with respect to r. The derivatives of the objective functions are (1)f (r), (2) f (r), (3) rf (r). All signs are negative when r(x) is less than 1. Usually, when x is sampled from q(x), r(x) is less than 1. Therefore, we speculate that r(x) is less than 1 during most of the learning process when x is sampled from q(x). When r(x) is small, the derivative is also small in (3) because the term r(x) is multiplied. Therefore, the derivative tends to be small in (3). The mechanism pulling r(x) to 1 does not work when r(x) is small. Thus, the case of (3) does not work well. A similar argument was proposed by Goodfellow et al. (2014) and Nowozin et al. (2016). In our experimental case of (1) and (2) work properly (Section 5). The reason case (2) works is that functionf (r) behaves like an f-divergence and the derivative is large when r(x) is small. However, we cannot guarantee that f (r) satisfies the conditions of f-divergence between positive measures, i.e,f (r) is a convex function andf (1) = 0. If the derivatives in case (2) are negative when r(x) is greater than 1, there is a possibility that the mechanism pulling r(x) to 1 does not occur. In contrast, in case (1), when r(x) is greater than 1, the derivatives are positive, therefore, the mechanism pulling r(x) to 1 occurs. This prevents generators from emitting the same points. We can expect the same effects as -minibatch discrimination- (Salimans et al., 2016). Throughout the analysis, we can easily extend the algorithm of b-GAN by using different divergences in the G-step and D-step. The original GAN can be regarded as one of such algorithms.",
      "exclude": false
    },
    {
      "heading": "4 ALGORITHMS FOR SPECIFIC CASES",
      "text": "We adopt -divergence in the positive measure space as the f-divergence (Amari & Cichoki, 2010). Here, we explain specific algorithms when f is -divergence. Then, we explain some heuristics used in b-GAN. 4.1 ALGORITHMS WITH -DIVERGENCE In -divergence, f(r) in Eq. 1 is f(r) = 4 12 (1 r 1+ 2 ) + 21 (r 1) ( 6= 1) r log r r + 1 ( = 1) log r + r 1 ( = 1). (8) The objective function derived from -divergence is summarized as follows.",
      "exclude": false
    },
    {
      "heading": "4.2 HEURISTICS",
      "text": "We describe some heuristic methods that work for our experiments. The heuristics introduced here are justified theoretically in Appendix C. In the initial learning process, empirical distribution p and generated distribution q are completely different. Therefore, the estimated density ratio r(x) = p(x)q(x) is enormous when x is taken from p and tiny when x is taken from q. It seems that the learning does not succeed in this case. In fact, in our setting, when the final activation function of rD (x) is taken from functions in the range (0,), b-GAN does not properly work. Therefore, we use a scaled sigmoid function such as a two-times sigmoid function. A similar idea has also been used in (Cortes et al., 2010). As mentioned, density ratio p(x)q(x) is extremely sensitive. To avoid this problem, in the D-step of the KL-divergence, we also conducted experiments wherein we estimated pp+(1)q (where is small.) rather than p(x)q(x) . The same idea is introduced in the covariate shift situation (Sugiyama et al., 2013). A similar idea has also been used for GAN learning (Salimans et al., 2016) and class probability estimation (Reid & Williamson, 2010).",
      "exclude": false
    },
    {
      "heading": "5 EXPERIMENTS",
      "text": "We conducted experiments to establish that the proposed algorithm works properly and can successfully generate natural images. The proposed algorithm is based on density ratio estimation; therefore, knowledge regarding the density ratio estimation can be utilized. In the experiments, using the Pearson divergence and estimating the relative density ratio is shown to be useful for stable learning. We also empirically confirm our statement in Section 3.4, i.e., f-divergence is increased when learning D and decreased when learning G.",
      "exclude": false
    },
    {
      "heading": "5.1 SETTINGS",
      "text": "We applied the proposed algorithm to the CIFAR-10 data set (Krizhevsky, 2009) and Celeb A data set (Liu et al., 2015) because they are often used in GAN research (Salimans et al., 2016; Goodfellow et al., 2014). The images size are 32 32 pixels. All results in this section are analyzed based on the results of the CIFAR-10 data set. The results for the Celeb A data set are presented in Appendix B. Our network architecture is nearly equivalent to that of previous study (Radford et al., 2015) (refer to the appendix A,B for details). Note that unless stated otherwise, the last layer function of rD (x) is a sigmoid function multiplied by two. We used the TensorFlow for automatic differentiation (Abadi et al., 2015). For stochastic optimization, Adam was adopted (Kingma & Ba, 2014).",
      "exclude": false
    },
    {
      "heading": "5.2 RESULTS",
      "text": "Figure 2 shows the density ratio estimate rD (x) and loss values of the generators. For each divergence, we conducted four experiments with 40,000 epochs, where the initial learning rate value was fixed (5 105) with the exception of reversed KL divergence. These results show that the b-GANs using Pearson divergence are stable because the learning did not stop. The same results have been reported in the research into density ratio estimation (Yamada et al., 2011). In contrast, b-GANs using the KL divergence are unstable. In fact, the learning stopped between the 20,000th and 37,000th epoch when the learning rate was not as small. When we use a heuristic method, i.e., estimating the relative density ratio as described in Section 4.2, this problem is solved. For reversed KL divergence, the learning stopped too soon if the initial learning rate value was 5 105. If the learning rate was 1 106, the learning did not stop; however, it was still unstable. In Figure 2, the last layer activation function of the b-GANs is a twofold sigmoid function. In Figure 3, we use a sigmoid function multiplied by five. The results indicate that the estimated density ratio values approach one. We also confirm that the proposed algorithm works with sigmoid functions at other scales. Figure 4 shows the estimated f-divergence Df (qr||q) before the G-step subtracted by Df (qr||q) after the G-step. Most of the values are greater than zero, which suggests f-divergence decreases at every G-step iteration. This observation is consistent with our analysis in Section 3.4. Note that learning is successful with an f-GAN-like update when minimizing Eq[f (r)]. However, the learning f-GAN-like update when minimizing Eq[f(r) rf (r)] did not work well for our network architecture and data set.",
      "exclude": false
    },
    {
      "heading": "6 CONCLUSIONS AND FUTURE WORK",
      "text": "We have proposed a novel unified algorithm to learn a deep generative model from a density ratio estimation perspective. Our algorithm provides the experimental insights that Pearson divergence and estimating relative density ratio are useful to improve the stability of GAN learning. Other insights regarding density ratio estimation would also be also useful. GANs are sensitive to data sets, the form of the network and hyper-parameters. Therefore, providing methods to improve GAN learning is meaningful. Related research to our study that focuses on linking density ratio and a GAN, has been performed by explaining specific algorithms independently (Mohamed & Lakshminarayanan, 2016). In contrast, our framework is more unified. In future, the following things should be considered. What is the optimal divergence? In research regarding density ratio estimation, the Pearson divergence ( = 3) is considered robust (Nam & Sugiyama, 2015). We empirically and theoretically confirmed the same property when learning deep generative models. It is also reported that using KL-divergence and reversed KL-divergence is not robust as scoring rules (Dawid et al., 2015). For generating realistic images, the reversed KL divergence ( = 1) is preferred because it is mode seeking (Huszar, 2015). However, if is small, the density ratio estimation becomes inaccurate. For a robust density ratio, using power divergence has also been proposed (Sugiyama et al., 2012). The determination of the optimal divergence is a persistent problem (Appendix E). What should be estimates in D-step? In the D-step of b-GAN, r(x) is estimated. However, in the original GAN, r(x)/(1 + r(x)) is estimated. As unnormalized models, the latter is more robust than estimating r(x) (Pihlaja et al., 2010) (Appendix E.7). We can consider algorithms that use different divergences in the G-step and D-step. In that case, choice of the divergences are more diverse. Original GANs are described in such algorithms as mentioned in Section 3.5. We can consider algorithms that use multiple divergences. This may improve the stability of learning. When sampling from q(x), if the objective is sampling from real data p(x), r(x) should be multiplied. Hence, the density ratio is also useful when using samples from q(x). How to use samples obtained from generators meaningfully is an remaining important problem.",
      "exclude": true
    },
    {
      "heading": "ACKNOWLEDGEMENTS",
      "text": "The authors would like to thank Masanori Misono for technical assistance with the experiments. We are grateful to Masashi Sugiyama, Makoto Yamada, and the members of the Preferred Networks team.",
      "exclude": false
    },
    {
      "heading": "A CIFAR-10 DATASET",
      "text": "Figure 5 shows samples generated randomly using b-GANs. These results indicate that b-GANs can create natural images successfully. We did not conduct a Parzen window density estimation for the evaluations because of Theis et al., [2016]. Here, we describe the network architecture of rD (x) and GG(z) used in the b-GAN. BN is the batch normalization layer (Sergey & Christian, 2015). A.1 rD (x) x Conv(3, 64) lRelu Conv(64, 256) BN lRelu Conv(256, 512) BN lRelu Reshape(4 4 512) Linear(4 4 512, 1) 2 Sigmoid A.2 GG(z) z Linear(100,4 4 512) BN Relu Reshape(4, 4, 512) Conv(512, 256) BN Relu Conv(256, 64) BN Relu Conv(64, 3) tanh",
      "exclude": false
    },
    {
      "heading": "B CELEB A DATASET",
      "text": "We also applied our algorithm to the Celeb A data set. The images are resized and cropped to 64 64 pixcels. Figures 6 and 7 show samples randomly generated using b-GANs. The Network architecture is as follows. B.1 rD (x) x Conv(3, 64) lRelu Conv(64, 128) BN lRelu Conv(128, 256) BN lRelu Conv(256, 512) BN lRelu Reshape(4 4 512) Linear(4 4 512, 1) 2Sigmoid B.2 GG(z) z Linear(64, 4 4 512) BN Relu Reshape(4, 4, 512) Conv(512, 256) BN Relu Conv(256, 128) BN Relu Conv(128, 64) BN Relu Conv(64, 3) tanh",
      "exclude": false
    },
    {
      "heading": "C PROOF OF PROPOSITIONS IN SECTION 3",
      "text": "",
      "exclude": false
    },
    {
      "heading": "C.1 PROOF OF PROP 3.1",
      "text": "From Eq. 4, the following equation holds, Exp [f (r(x))] Exq[(f (r(x))r(x) f(r(x)))] = BDf (r||r) + Eq [ f ( p(x) q(x) )] . (9) Using BDf (r||r) 0 yields Eq. 7. We have BDf (r||r) = 0 when r is equal to r. Thus, the equality holds if and only if r is equal to r.",
      "exclude": false
    },
    {
      "heading": "C.2 PROOF OF PROP3.2",
      "text": "r.h.s of Eq.2 = Exp(x)[f (r(x))] Exq(x)[f (f (r(x)))] (10) = Exp(x)[f (r(x))] Exq(x)[f(r(x))r(x) f(r(x))] = Exp(x)[f (r(x))] Exq(x)[(f (r(x))r(x) f(r(x)))] = the negative of Eq. 5 In the derivation, we have used the following equation f ( f (r(x)) ) = f(r(x))r(x) f(r(x)) .",
      "exclude": false
    },
    {
      "heading": "D EXPLANATION OF HEURISTICS USING RADEMACHER COMPLEXITY",
      "text": "Here, we justify three points using Rademacher complexity. All techniques used are described in the literature (Mohri et al., 2012). Pearson divergence is preferable to KL divergence in density ratio estimation. Relative density ratio is useful (introduced in Sec 4.2). The meaning of bounding the last output functions of discriminators (introduced in Sec 4.2). Our objective is estimating r(x) = p(x)q(x) . We define hypothesis sets as H. In Section 3.4, we assume H as parametric models for simplicity. In this section, we do not restrict H to parametric models. We define r0 and rs as r0 = argminhHBRf (h) rs = argminhHBRf (h), where BR is an empirical approximation of BR. Note that BRf (h) reaches minimum values if and only if r = h holds. We want to analyze BRf (rs)BRf (r). The regret, i.e., BRf (rs)BRf (r) can be bounded as follows: BRf (rs)BRf (r) = BRf (rs)BRf (r0) +BRf (r0)BRf (r) 2 sup hH |BRf (h) BRf (h)|+BRf (r0)BRf (r). (11) The first term of Eq. 11 is bounded by uniform law of large numbers. To do that, assume that all elements in H are bounded by constant C. First, we consider the case when f is the Pearson divergence. In that case, BRf (h) is Exp(x)[0.5h(x) 2] Exq(x)[h(x)]. (12) We denote the Rademacher complexity of H as Rm,q when x is sampled from q(x) and the sample size is m. The first term of Eq. 12 is upper bounded by Talagrands lemma. For any with probability as least 1 , we have sup hH |Exp(x)[0.5h(x)2] 1 m 0.5h(xi) 2| CRm,p(H) + 0.5C2 log 1 2m , (13) where samples are taken from p(x) independently. the fact that 0.5h(x)2 is C-Lipchitz over the interval (0, C) is used (C is a constant real number). The first term of Eq. 12 is upper-bounded by Talagrands lemma. For any with probability at least 1 , we have sup hH |Exq(x)[h(x)] 1 m h(xi)| Rm,q(H) + C log 1 2m , (14) where samples are taken from q(x) independently. By combining Eq. 13 and Eq. 14, for any with probability as least 1 , the first term of Eq. 11 is bounded by 2CRm,p(H) + 2Rm,q(H) + (C2 + 2C) log 12 2m . (15) When f is the KL-divergence, BRf (h) is Exq(x)[h(x)] Exp(x)[log h(x)]. (16) The second term of Eq. 16 cannot be bounded because log(x) is no longer Lipchitz continuous over (0, C). This explains why Pearson divergence is preferable to KL divergence in density ratio estimation. However, if h(x) is lower-bounded by the constant real number C, the problem is solved. Using the relative density ratio has the same effect. In our setting, r(x) is a sigmoid function multiplied by C. If C is large, the approximation error, i.e., BRf (r0)BRf (r) is small. However, there is a possibility that the estimation error increases according to Eq. 15, which may lead to the learning instability.",
      "exclude": false
    },
    {
      "heading": "E SUMMARY OF DENSITY RATIO ESTIMATION RESEARCH",
      "text": "In this section, we review researches related to density ratio estimation, entangling them to b-GAN. The Eq. 4 has also been used in class probability density estimation and unnormalized models research. We briefly describe research that is closely connected to density ratio estimation and extract ideas that can also be applied to b-GAN.",
      "exclude": false
    },
    {
      "heading": "E.1 NOTATION",
      "text": "We summarize notations frequently used in this section. r(x) = p(x)/q(x) Density ratios between p(x) and q(x). In b-GAN, p(x) is the probability density function of real data and q(x) is the probability density function of generated data. x(n)i Samples taken from p(x). x(d)i Samples taken from q(x). D = (p, q, ) The joint distribution of X and Y . The variable X has the the mixture distribution of p + (1 )q and Y is a binary label taking values in 1,+1 which satisfies = P (Y = 1); thus, (p, q) = (P (X|Y = 1), P (X|Y = 1)) holds. The Bayes optimal estimator P (Y = 1|X) for binary classification. l : 1, 1 [0, 1] R Loss function h1 : X [0, 1] An element of hypothesis sets. In this case, the objective is estimating P (Y = 1|x). hg : X V An element of hypothesis sets. V is a subset of R. Note that h1 is a special case of hg . : [0, 1] V A link function. k(x, ) A positive definite and characteristic (Fukumizu et al., 2004) kernel on the measurable space ofR. Hk A reproducing kernel Hilbert space with a kernel k (Steinwart, 2011). An inner product in Hk is , . : R Hk A characteristic function:x k(x, ). Xp A random variable with probability density function p. Bf [pq] Bregman divergence with f between p and q.",
      "exclude": false
    },
    {
      "heading": "E.2 THEORETICAL ASPECTS OF DENSITY RATIO ESTIMATION",
      "text": "Following Kanamori et al. (2012), we expand the explanation of density ratio estimation. As noted in Section 3, the objective function of density ratio estimation is BRf (r) = 1 n n i=1 ( f (r(x (d) i ))r(x (d) i ) f(r(x (d) i )) ) 1 n n i=1 f ( r(x (n) i ) ) , (17) which is an empirical approximation of Eq. 5. The estimator n is obtained by minimizing Eq. 17. The estimator n is an M-estimator because Eq. 17 is a form of 1n n i=1m(x), where m is a function of x and x (xdi , xni ) holds. The estimator n satisfies consistency under mild conditions (see Prop 7.4. (Hayashi, 1997)). The essential condition is the expectation of Eq. 17 is uniquely minimized when r is equivalent to the true density ratio r. We have proved that proposition in Appendix D. Asymptotic normality also holds under suitable conditions (see Prop 7.8. (Hayashi, 1997)). By differentiating Eq. 17 with respect to , the above method can be regarded as a type of moment matching as follows: BRf (r) = 1 n n i=1 f (r(x (d) i )r (x (d) i )r(x (d) i ) 1 n n i=1 f (r(x (n) i ))r (x (n) i ). (18) The estimator n is attained when Eq.18 is equal to 0. By substituting f (r(xi)r(xi) with s(xi), Eq. 18 is reduced to be 1 n n i=1 s(x (d) i )r(x (d) i ) 1 n n i=1 s(x (n) i ). (19) The above Eq. 18 is a form of moment matching.1 What is the optimal s(x)? Here, we focus on the variance of the estimator (efficiency). It is known that the Eq. 17 derived from the logistic model is known to be optimal (Qin, 1998). It is a natural consequence because the logistic model can be considered as a maximum likelihood and maximum likelihood reaches the Cramer-Rao bound asymptotically. Typically, general moment matching (GMM) achieves the lower bound when the estimating equation is the score of observations, i.e., when GMM is identical to maximum likelihood. Efficiency is not the absolute criterion for choosing losses. For example, when there are many outliers in the data, robustness is more important than efficiency. In reality, an M estimator was introduced in the contest of robust statistics (Huber & Ronchetti, 2009).",
      "exclude": false
    },
    {
      "heading": "E.3 CLASS PROBABILITY ESTIMATION",
      "text": "We have explained density ratio estimation, starting with the Bregman divergence. Importantly, density-ratio estimation is equivalent to class probability estimation. For details, see (Reid & Williamson, 2011; 2010; Dawid & Musio, 2014; Menon & Ong, 2016). As in Section E.1, we introduce the variable Y . The joint distribution of X and Y is denoted as D = (p, q, ). Class probability estimation can be regraded as a minimization problem of the empirical estimation of the full risk E(X,Y )D[l(Y, h1)], which is denoted L(h1;D, l) (h1 is a hypothesis element). When the hypothesis h1, which minimizes E(X,Y )D[l(Y, h1)], is the Bayes optimal estimator (x) uniquely, such a loss is called a proper loss. A proper loss is naturally extended to a composite proper loss by introducing a link function . In this case, the objective is estimating ((x)) correctly. The estimator is obtained by the empirical minimization of full risk E(X,Y )D[l(Y, hg)] when l(Y, hg) means l(Y,1(hg(x))) and (h1(x)) is the same as hg(x). When the hypothesis hg(x), which minimizes E(X,Y )D[l(Y, hg)], is the Bayes optimal estimator ((x)) uniquely, such a loss is called a proper composite loss with a link function . The conditional risk (conditioned on x) EY[l(Y, hg)] can be decomposed to EY[l (Y, hg)] = L1(h g) + (1 )L1(hg). (20) The conditional Bayes risk is L1(((x))) + (1 )L1(((x))) = +1() + (1 )1(), (21) where +1(x) = L1((x)) and 1(x) = L1((x)). We set Eq. 21, i.e., x+1(x)+(1x)1(x) as c(x). The regret of the composite proper loss can be written using Bregman divergence L(hg;D, l) L( ;D, l) = EX [ Bc [ (X)1(hg(X)) ]] . (22) 1In usual moment matching, s(x) is not be dependent on the form of probability density function. However, it depends on the form of r in this case. The problem of minimizing the composite proper loss turns out be the density ratio estimation problem by setting (x) as u/(1 u) and = 0.5 (Menon & Ong, 2016). In this case, the LHS of Eq. 22 can be written as EXq [Bc [((X))hg(X)]] (((X)) = r(x)), where c is given by c : x (1 + x)c ( x 1 + x ) . The equation EXq [Bc [r(X)hg(X)]] corresponds to Eq. 4 by substituting c with f and hg with r. What loss is the optimal loss? The above loss can be written in another form using weight by transforming Eq. 22 further. Determining what loss is better has been analyzed from the perspective of weight. For example, Reid & Williamson (2010) proposed the minimal symmetric convex proper loss for surrogate loss. Regarding density ratio, Menon & Ong (2016) suggest that Pearson divergence is robust because the weight of Pearson divergence is uniform. However, according to their covariate shift experiment, Pearson divergence was not significantly superior to other divergence. What is the difference between density ratio estimation (class probability estimation) and classification? The objective and assumption differ. As for assumption, in density ratio, the situation where p(x) and q(x) are overlapping would be preferable. However, in classification, the situation where p(x) and q(x) separate would be preferable. In addition, the objective of classification is slightly different from estimating a Bayes rule correctly. Margin loss is widely used in classification rather than zero-one loss. The theoretical guarantee of using margin loss for classification is that it is included in class calibrated loss (Bartlett et al., 2006). However, the margin loss is not equivalent to a proper loss, i.e, it is often not suitable for estimating . The condition whereby margin loss is a proper loss is explained by Reid & Williamson (2010). A GAN using margin loss has been proposed (Zhao et al., 2016). Note that using margin loss is not supposed in b-GAN. They succeeded in generating high resolution images.",
      "exclude": false
    },
    {
      "heading": "E.4 ROBUST LOSS AND DIVERGENCE",
      "text": "What is robust loss and divergence? Basu et al. (1998) proposed a robust divergence called power divergence (Basu et al., 1998), which is given as B [pq], where is (x) = 1 ( + 1) (x+1 ( + 1)x+ ). (23) This is also called -divergence (Amari & Cichoki, 2010). The robust estimation equation is derived from power divergence compared to maximum likelihood. By setting f as , robust density ratio estimation has been proposed (Sugiyama et al., 2012). In this case, the objective function is Exq(x)[B [rr]]. Dawid et al. (2015) analyze robust proper loss from the perspective of influence function. They proposed a concept of B-robustness from the perspective of influence function. It is stated that using KL divergence and reversed KL divergence is not robust because the second derivative of f is not bounded at 0. That is a similar conclusion to our analysis in Appendix D.",
      "exclude": false
    },
    {
      "heading": "E.5 KERNEL METHODS",
      "text": "We assume that k(x, ) is a positive definite kernel. When X is a random variable taking values inR and (X) is a random variable taking values inHk with a characteristic map : x k(, x), we can think of the mean of random variable (X) denoted as mkX taking values inHk, which satisfy f,mkX = E[f,(X)] = E[f(x)](f Hk) and mkX(y) = mkX , k(, y) = E[k(X, y)]. If the kernel is characteristic, the bijective from all measures onR to Hk exists such that a measure p(x)dx corresponds to the mean mkXp (Fukumizu et al., 2004). When there are random variables Xp and Xq , we can measure the distance between Xp and Xq by calculating mkXp m k Xq 2Hk . As the density ratio estimation methods using kernels, the objective function is the empirical approximation of mkXqr m k Xp 2Hk . As generative moment matching networks (GMMN), the objective function is mkXq m k Xp 2Hk (Dziugaite et al., 2015; Li et al., 2015). GMMNs seem to be superior to b-GAN because they can be trained without density ratio. However, the choice of kernels is difficult. In addition, an autoencoder appears to be required for generating complex data.",
      "exclude": false
    },
    {
      "heading": "E.6 F-DIVERGENCE ESTIMATION AND TWO SAMPLE TEST",
      "text": "We consider the problem of f-divergence estimation between p(x) and q(x). This is applied straightforwardly to a two-sample test. Variational f-divergence estimation using Eq. 3 is proposed (Nguyen et al., 2010). In addition, the two step method, i.e., first estimating density ratio and then estimating f-divergence, is proposed (Kanamori et al., 2012). This method is also applied to a two-sample test. The latter method is similar to b-GAN. A kernel two sample test is also introduced calculating mkXq m k Xp 2Hk in (Gretton et al., 2012).",
      "exclude": false
    },
    {
      "heading": "E.7 UNNORMALIZED MODELS",
      "text": "When the model p0(xm;) is unnormalized, the unified method including noise contrastive estimation was proposed in (Pihlaja et al., 2010; Gutmann & Hirayama, 2011; Gutmann & Hyvarinen, 2010). In this case, the objective is estimating = ,C when the log-likelihood of normalized model log p(x; ) is equal to log p0(x;) + C and C is a normalizing constant. Compared to b-GAN, the auxiliary distribution q(x) is known. The parameter can be estimated as a minimization problem of Eq. 17 by replacing r(x) with p(x; )/q(x) (Pihlaja et al., 2010). As similar algorithm, the method estimating r first, then estimating p(x; ) as r(x)q(x) is suggested by Gutmann & Hirayama (2011). Note that the latter method is similar to b-GAN. Pihlaja et al. (2011) analyzed what loss is better by differentiating loss. They experimentally confirmed that noise contrastive estimation is robust with respect to the choice of the auxiliary distribution.",
      "exclude": false
    }
  ],
  "fewShot": [
    {
      "model": "claude-haiku-4-5",
      "decision": {
        "rejection": false,
        "confidence": 0.72,
        "primary_reason": "Novel theoretical framework connecting GANs to density ratio estimation with rigorous mathematical analysis and empirical validation across multiple divergences."
      },
      "token": {
        "prompt_tokens": 9860,
        "completion_tokens": 61,
        "total_tokens": 9921
      },
      "time": "2026-02-08T22:29:18.768520+00:00"
    },
    {
      "model": "gpt-5.2",
      "decision": {
        "rejection": true,
        "confidence": 0.72,
        "primary_reason": "Interesting unifying view of GANs as alternating density-ratio estimation and f-divergence minimization, but the core contribution is largely a re-derivation/reframing of existing GAN/f-GAN ideas with limited demonstrated empirical advantage: experiments are mostly qualitative on CIFAR-10/CelebA, lack strong quantitative metrics and comparisons to contemporary GAN baselines, and rely on several heuristics (scaled sigmoid, relative ratio) without a compelling, general improvement storyâ€”so impact/novelty and evaluation depth likely fall below ICML/ICLR/NeurIPS bar."
      },
      "token": {
        "prompt_tokens": 11129,
        "completion_tokens": 145,
        "total_tokens": 11274
      },
      "time": "2026-02-09T20:31:37.576459+00:00"
    }
  ],
  "test": false
}